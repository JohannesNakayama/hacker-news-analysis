---
title: "Hacker News Analysis"
date: "2021-01-18"
output: 
  prettydoc::html_pretty:
    theme: tactile
---

```{r setup, include=FALSE}

# defaults and libraries
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(tidyverse)
library(magrittr)
library(ggpubr)
source("helpers.R")

```



```{r read-data}

if (!("hn-data-processed.rds" %in% list.files(file.path("..", "data")))) {
  data <- read.table(file.path("..", "data", "hn-data-2.tsv"), sep = "\t", header = TRUE)
  data %<>% 
    mutate(rank = as.numeric(rank),
           age = sample_time - submission_time) %>% 
    mutate(subtime_datetime = lubridate::as_datetime(submission_time, tz = "CET"),
           samptime_datetime = lubridate::as_datetime(sample_time, tz = "CET")) %>% 
    mutate(subtime_y = lubridate::year(subtime_datetime),
           subtime_m = lubridate::month(subtime_datetime),
           subtime_d = lubridate::day(subtime_datetime),
           subtime_h = lubridate::hour(subtime_datetime),
           subtime_m = lubridate::minute(subtime_datetime),
           subtime_s = lubridate::second(subtime_datetime),
           samptime_y = lubridate::year(samptime_datetime),
           samptime_m = lubridate::month(samptime_datetime),
           samptime_d = lubridate::day(samptime_datetime),
           samptime_h = lubridate::hour(samptime_datetime),
           samptime_m = lubridate::minute(samptime_datetime),
           samptime_s = lubridate::second(samptime_datetime)) %>%
    mutate(subtime_clocktime = update(subtime_datetime, yday = 1)) %>% 
    select(-c(submission_time, sample_time))
  write_rds(data, file.path("..", "data", "hn-data-processed.rds"), compress = "gz")  
} else {
  data <- read_rds(file.path("..", "data", "hn-data-processed.rds"))  
}

```

```{r helper-functions}

get_id_selector <- function(data) {
  data %>% 
    filter(age < 120) %>% 
    select(id) %>% 
    unique() -> id_selector  
  return(id_selector)
}

# subset the data by a random sample of IDs
get_random_sample <- function(data, n) {
  id_selector <- get_id_selector(data)
  if (dim(id_selector)[1] < n) {
    stop("n is too large")
  }
  data %>% inner_join(id_selector %>% sample_n(n), by = "id")   
}

# subset the data by the first n IDs that occurred 
get_first_n <- function(data, n) {
  id_selector <- get_id_selector(data)
  if (dim(id_selector)[1] < n) {
    stop("n is too large")
  }
  data_sample <- data %>% inner_join(head(id_selector, n), by = "id")  
  return(data_sample)
}

```

```{r, message=TRUE}

get_first_n(data, 100)
get_random_sample(data, 100)

```


# Distribution of Submissions over Time


Over the entire sample space

```{r}

data %>% 
  ggplot(aes(x = subtime_datetime)) +
  geom_density(color = "white", fill = "white", alpha = 0.5) +
  theme_hn()

```


By time of day

```{r}

data %>% 
  ggplot(aes(x = subtime_clocktime)) +
  geom_density(color = "white", fill = "white", alpha = 0.5) +
  theme_hn()

```


# Distribution of Ages on the Top Page


```{r}


data %>% 
  filter(!is.na(rank)) %>% 
  filter(rank <= 30) %>% 
  ggplot(aes(x = age / 60 / 60)) +
  geom_histogram(fill = "white", alpha = 0.5) +
  theme_hn()




```

```{r}

# TODO: ANIMATE DISTRIBUTION OF TOPPAGE AGES OVER TIME

```


 Oldest story on the Top Page

```{r}

get_max_age <- function(data, max_rank) {
  data %>% 
    filter(!is.na(rank)) %>% 
    filter(rank <= max_rank) %>% 
    mutate(age_hours = age / 60 / 60) %>% 
    select(age_hours) %>% 
    max()  
}

get_max_age(data, 30)
get_max_age(data, 100)
get_max_age(data, 500)

```

Hard cut-off after 48 hours? Or scraping specification?







































