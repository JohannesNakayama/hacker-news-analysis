---
title: "Hacker News Analysis"
date: "2021-01-18"
output: 
  prettydoc::html_pretty:
    theme: tactile
---

```{r setup, include=FALSE}

# defaults and libraries
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(tidyverse)
library(magrittr)
library(ggpubr)
source("helpers.R")

```


# Analysis of Required Sampling Rate

For any analysis of Hacker News over a period of time, it is first important to know at which rate the stories need to be sampled. The following plot displays the top 10 stories from Hacker News over the period of one hour. As can be seen, The developments are not as volatile as to require a sampling rate of 2 or 4 minutes. Even with a six minute sampling rate, the developments are still depicted reasonably accurately. For the further analyses, I chose a sampling rate of 5 minutes.

```{r load-and-format-sampling-rate-data}

# read data
h1_data <- arrow::read_feather(file.path("..", "data", "h1_data.feather"))
eda_data <- arrow::read_feather(file.path("..", "data", "eda_data.feather"))

# format data
h1_data %<>% 
  mutate(id = as.factor(id),
         creation_time = as.POSIXct(creation_time, origin = "1970-01-01", tz = "UTC"), 
         score = as.numeric(score),
         comment_count = as.numeric(comment_count),
         timestamp = as.POSIXct(timestamp, origin = "1970-01-01", tz = "UTC"),
         rank_at_timestamp = as.ordered(rank_at_timestamp))

eda_data %<>% 
  mutate(id = as.factor(id),
         creation_time = as.POSIXct(creation_time, origin = "1970-01-01", tz = "UTC"), 
         score = as.numeric(score),
         comment_count = as.numeric(comment_count),
         timestamp = as.POSIXct(timestamp, origin = "1970-01-01", tz = "UTC"),
         rank_at_timestamp = as.ordered(rank_at_timestamp))

# add timestamp id (ordered factor of timestamps)
h1_data %>% 
  group_by(timestamp) %>% 
  summarize(timestamp = unique(timestamp)) %>%
  ungroup() %>% 
  arrange(timestamp) -> timestamp_ordering

timestamp_ordering$ts_id <- 1:dim(timestamp_ordering)[1]

h1_data %<>% inner_join(timestamp_ordering, by = "timestamp")

```

```{r sampling-rate-plot, fig.height=4, fig.width=7, fig.align="center", out.width="100%", dpi=300}

# generic styling
plot_details <- theme_hn() +
  theme(legend.position = "None",
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())

# plot individual plots
h1_data %>% 
  filter(rank_at_timestamp <= 10) %>% 
  ggplot(aes(x = timestamp, y = score, color = id)) +
  geom_point() +
  geom_line() +
  ggtitle("2 Minutes") +
  plot_details +
  theme(legend.position = "None", 
        plot.title = element_text(margin = margin(t = 10, b = 10))) -> p1

h1_data %>% 
  filter(rank_at_timestamp <= 10) %>% 
  filter(ts_id %% 2 == 0) %>% 
  ggplot(aes(x = timestamp, y = score, color = id)) +
  geom_point() +
  geom_line() +
  ggtitle("4 Minutes") +
  plot_details +
  theme(legend.position = "None",
        plot.title = element_text(margin = margin(t = 10, b = 10))) -> p2

h1_data %>% 
  filter(rank_at_timestamp <= 10) %>% 
  filter(ts_id %% 3 == 0) %>% 
  ggplot(aes(x = timestamp, y = score, color = id)) +
  geom_point() +
  geom_line() +
  ggtitle("6 Minutes") +
  plot_details +
  theme(legend.position = "None",
        plot.title = element_text(margin = margin(t = 10, b = 10))) -> p3

# arrange in one plot
ggarrange(p1, p2, p3, nrow = 1) %>% 
  annotate_figure(top = text_grob(label = "Development of Top 10 Stories for Different Sampling Rates",
                                  color = "grey20",
                                  size = 15),
                  left = text_grob(label = "Score",
                                   color = "grey20",
                                   rot = 90),
                  bottom = text_grob(label = "Timestamp",
                                     color = "grey20")) +
  theme(plot.background = element_rect(color = "grey70", fill = "grey70", size = 1),
        plot.margin = margin(15, 15, 15, 15)) +
  NULL

```


# What Happens on the `new` Page?

Presumably, the `new` page on Hacker News is the only way for newly created stories to gain traction. Hence, it is important to have a look at how large this window of opportunity is. 

```{r load-newstories-data}

# load new stories data
newstories <- arrow::read_feather(file.path("..", "data", "newstories.feather"))
newstories %<>%
  mutate(story_id = as.factor(story_id),
         timestamp = as.POSIXct(timestamp, origin = "1970-01-01", tz = "UTC"),
         rank = as.numeric(rank))

```

```{r plot-newstories-data, fig.align="center", out.width="100%", dpi=300}

# only consider ranks below 50
newstories %>% filter(rank <= 50) -> newstories_toppage
n_stories <- newstories_toppage$story_id %>% unique() %>% length()
color_scheme <- rep(c("black", "white"), n_stories)

# plot development of the "new" page
newstories_toppage %>% 
  ggplot(aes(x = timestamp, y = rank, color = story_id, alpha = 30 - rank)) +
  scale_color_manual(values = color_scheme) +
  geom_point(size = 1) +
  geom_line(size = 1) +
  scale_y_continuous(trans = "reverse", breaks = seq(50, 1, -5)) +
  theme(legend.position = "None") +
  geom_hline(yintercept = 30, linetype = "dashed", color = "red", size = 2) +
  labs(title = "Development of \"New\" Page",
       x = "Timestamp",
       y = "Rank") +
  theme_hn() +
  theme(plot.margin = margin(15, 15, 15, 15),
        panel.grid.minor.y = element_blank())

```


How many votes on new page?


Follow a sample of stories from the new page -> how do they develop? 
Do they get any upvotes after disappearing from the new page?

# The `top stories` Page



```{r load-and-format-top-story-data}

# load topstories data
topstories <- arrow::read_feather(file.path("..", "data", "topstories.feather"))
topstories %<>% 
  mutate(creation_time = lubridate::as_datetime(creation_time),
         score = as.numeric(score),
         comment_count = as.numeric(comment_count),
         scrape_timestamp = lubridate::as_datetime(scrape_timestamp),
         slice_timestamp = lubridate::as_datetime(slice_timestamp),
         rank_at_timestamp = as.numeric(rank_at_timestamp),
         age = as.numeric(scrape_timestamp - creation_time) / 3600)

```


```{r topstories-general-metrics}

# general metrics
n_stories <- topstories$id %>% unique() %>% length()
n_creators <- topstories$creator_username %>% unique() %>% length()
time_interval <- (max(topstories$scrape_timestamp) - min(topstories$scrape_timestamp)) %>% as.numeric()

```

There are `r n_stories` stories by `r n_creators` different users in the data set.
The data set covers a range of `r time_interval %>% round(2) %>% format(2)` in intervals of two minutes.

```{r topstories-delays}

topstories %>% 
  group_by(slice_timestamp) %>% 
  summarize(scraping_delay = max(scrape_timestamp) - min(scrape_timestamp)) -> delay_data

mean_delay <- delay_data$scraping_delay %>% mean() %>% as.numeric()
median_delay <- delay_data$scraping_delay %>% median() %>% as.numeric()
sd_delay <- delay_data$scraping_delay %>% sd()
max_delay <- delay_data$scraping_delay %>% max() %>% as.numeric()

```

Even though all topstories cannot be scraped at exactly the same time, there are only minor time delays in the scraping process, with a mean of `r mean_delay %>% round(2) %>% format(2)` seconds, a median of `r median_delay %>% round(2) %>% format(2)` seconds, and a standard deviation of `r sd_delay %>% round(2) %>% format(2)` seconds. The maximum delay was `r max_delay %>% round(2) %>% format(2)` seconds which is in an acceptable range.

```{r plot-scraping-delays, fig.align="center", out.width="100%", dpi=300}

delay_data %>% 
  ggplot(aes(x = scraping_delay)) +
  geom_histogram(fill = "white", alpha = 0.7) +
  labs(title = "Delays after the Intended Time Slice",
       x = "Scraping Delay",
       y = "Count") +
  theme_hn() +
  theme(plot.margin = margin(15, 15, 15, 15))

```

Scores and comment counts seem to be exponentially distributed as could be expected. Note that posts with more than 500 comments were excluded in the lower plot because of some extreme outliers that would have made the visual analysis of the remaining data difficult.

```{r plot-score-distribution, fig.align="center", out.width="100%", dpi=300}

topstories %>% 
  ggplot(aes(x = score)) +
  geom_histogram(fill = "white", alpha = 0.7) +
  labs(title = "Distribution of Scores (Overall)",
       x = "Score",
       y = "Count") +
  theme_hn() +
  theme(plot.margin = margin(15, 15, 15, 15))

```

```{r plot-comment-count-distribution, fig.align="center", out.width="100%", dpi=300}
topstories %>% 
  filter(comment_count < 500) %>% 
  ggplot(aes(x = comment_count)) +
  geom_histogram(binwidth = 10, fill = "white", alpha = 0.7) +
  labs(title = "Distribution of Number of Comments (Overall)",
       x = "Number of Comments",
       y = "Count") +
  theme_hn() +
  theme(plot.margin = margin(15, 15, 15, 15))

```

fit exponential distributions


## How Do Stories Develop that have at Some Point Reached Rank 1?

```{r rank-one-stories, fig.align="center", out.width="100%", dpi=300}

# up to which rank?
min_rank <- 160

# find ids of all stories that at some point reached rank 1
topstories %>% 
  filter(rank_at_timestamp == 1) %>% 
  select(id) %>% 
  unique() -> rank_one_joiner

# create a color scheme for maximum distinguishability
color_scheme <- sample(viridis::magma(dim(rank_one_joiner)[1]))

# plot data
topstories %>% 
  inner_join(rank_one_joiner, by = c("id")) %>% 
  mutate(rank_at_timestamp = as.numeric(rank_at_timestamp)) %>% 
  ggplot(aes(x = slice_timestamp, y = rank_at_timestamp)) +
  geom_line(aes(alpha = log(score)), size = 0.6) +
  scale_color_manual(values = color_scheme) +
  scale_y_continuous(trans = "reverse", limits = c(min_rank, 1)) +
  labs(title = "Development of Stories that Reached Rank 1",
       x = "Slice Timestamp",
       y = "Rank") +
  facet_wrap(. ~id) +
  theme_hn() +
  theme(plot.margin = margin(15, 15, 15, 15),
        legend.position = "None") +
  NULL

```

```{r rank-one-stories, fig.align="center", out.width="100%", dpi=300}

# up to which rank?
min_rank <- 160

# find ids of all stories that at some point reached rank 1
topstories %>% 
  filter(rank_at_timestamp == 1) %>% 
  select(id) %>% 
  unique() -> rank_one_joiner

# create a color scheme for maximum distinguishability
color_scheme <- sample(viridis::magma(dim(rank_one_joiner)[1]))

# plot data
topstories %>% 
  inner_join(rank_one_joiner, by = c("id")) %>% 
  mutate(rank_at_timestamp = as.numeric(rank_at_timestamp)) %>% 
  ggplot(aes(x = slice_timestamp, y = score, color = id)) +
  geom_line(size = 0.6, alpha = 0.6) +
  scale_color_manual(values = color_scheme) +
  # scale_y_continuous(trans = "reverse", limits = c(min_rank, 1)) +
  labs(title = "Development of Stories that Reached Rank 1",
       x = "Slice Timestamp",
       y = "Rank") +
  theme_hn() +
  # facet_wrap(. ~ id) +
  # theme(plot.margin = margin(15, 15, 15, 15), 
  #       legend.position = "None") +
  NULL

```



```{r}

topstories %>% 
  filter(id == "25761068") %>% 
  select(slice_timestamp, rank_at_timestamp, score) %>% 
  arrange(slice_timestamp)


topstories %>% 
  filter(id == "25761068") %>% 
  ggplot(aes(x = score, y = rank_at_timestamp)) +
  geom_point()





```



```{r}

topstories %<>% mutate(age = as.numeric(scrape_timestamp - creation_time) / 3600)

topstories %>% 
  filter(score <= 3) %>% 
  select(id) %>% 
  unique() %>% 
  sample_n(40) -> small_score_ids

topstories %>% 
  inner_join(small_score_ids, by = "id") %>% 
  ggplot(aes(x = age, y = rank_at_timestamp, color = as.factor(id), alpha = score)) +
  scale_y_continuous(trans = "reverse") +
  geom_line() +
  theme(legend.position = "None")

```




# Maximum Age for Top Stories

```{r}

df <- data.frame()

for (n in c(1, 10, 30, 100)) {
  df %<>% 
    rbind(
      topstories %>% 
        filter(rank_at_timestamp <= n) %>% 
        select(age) %>% 
        mutate(top_n = n)       
    )
}

df %>% 
  ggplot(aes(x = age, color = as.factor(top_n))) +
  geom_boxplot() +
  coord_flip()


```




# Remaining Questions


  * Maximum age for top stories?  
  * All new stories in top stories?  
  * Minimum number of votes to make the top list  
  * How frequently do the strange jumps occur?
  * Is the new page really the window of opportunity? Does occurring on the new page impact the later success of the story?
  
Are there statistics about page visits? -> moderators
How many votes are casted on the new / top page?



Validation:

  * simulate and compare


Goal:

View on what happens that is transferrable between real data and simulated data


Longterm:

  * Stackoverflow




scrape new and top stories in parallel
fix bug that makes program get stuck
Zwischenstände speichern und einfach laufen lassen








```{r}

data <- read.table(file.path("..", "data", "hn-data.tsv"), sep = "\t", header = TRUE)

data$rank %<>% as.numeric()

data %<>% mutate(age = sample_time - submission_time)

```


```{r}


data %>% 
  filter(age < 360) %>% 
  select(id) %>% 
  unique() -> id_selector


get_sample <- function(data, id_selector, n) {
  data %>% 
    inner_join(id_selector %>% sample_n(n), by = "id")   
}


data_sample <- data %>% 
    inner_join(head(id_selector, 1000), by = "id")  


data_sample %>% 
  ggplot(aes(x = as.numeric(sample_time), y = as.numeric(rank), color = as.factor(id))) +
  geom_line() +
  scale_y_continuous(trans = "reverse") +
  scale_x_continuous(breaks = seq(min(data_sample$sample_time), max(data_sample$sample_time), by = 3600)) +
  coord_flip() +
  theme(legend.position = "None",
        axis.text.x = element_text(angle = 90))

data_sample %>% 
  filter((sample_time > 1611491037) & (sample_time < 1611523437)) %>% 
  ggplot(aes(x = as.numeric(sample_time), y = as.numeric(rank), color = as.factor(id))) +
  geom_line() +
  scale_y_continuous(trans = "reverse") +
  scale_x_continuous(breaks = seq(min(data_sample$sample_time), max(data_sample$sample_time), by = 3600)) +
  coord_flip() +
  theme(legend.position = "None",
        axis.text.x = element_text(angle = 90))

dir.create("graphics")
ggsave(file.path("graphics", "time_vs_rank.png"))

data %>% 
  inner_join(id_selector %>% sample_n(50), by = "id") %>% 
  ggplot(aes(x = as.numeric(sample_time), y = as.numeric(score), color = as.factor(id))) +
  geom_line() +
  scale_y_log10() +
  # scale_y_continuous(trans = "reverse") +
  theme(legend.position = "None")

```


Zeitplots von verschiedenen Metriken/Statistiken -> korrelieren Ereignisse? 

Aufkommen von New Stories
Score
Rank
Age

Top 10 (20, 30, ...) -> Relation Rank / Score?
plot Scores als Labels

Zeit gegen Score -> andere Farbe wenn über gewissen Rank
Rank nach Farbe


```{r}


data_sample <- data %>% inner_join(head(id_selector, 50), by = "id")  

data_sample <- get_sample(data, id_selector, 5)

data_sample %>% 
  ggplot(aes(x = sample_time, y = score, color = rank, group = id)) +
  geom_jitter(alpha = 0.3, width = 1.5) +
  # geom_line() +
  scale_y_log10() +
  # scale_color_continuous(type = grDevices::rainbow(500))
  # scale_color_gradient(low = "blue", high = "red") +
  scale_color_gradientn(colours = rainbow(10))
  NULL

```



```{r}

data %>% 
  inner_join(id_selector %>% sample_n(50), by = "id") %>% 
  ggplot(aes(x = as.numeric(score), y = as.numeric(rank), color = as.factor(id))) +
  geom_line() +
  scale_y_continuous(trans = "reverse") +
  theme(legend.position = "None")

```


```{r}

single_story <- get_sample(data, id_selector, 1)

max(single_story$rank)

```
















































