mutate(rank_newpage = row_number()) %>%
ungroup() %>%
arrange(samptime_datetime_rounded) %>%
mutate(on_toppage = !is.na(rank_toppage))%>%
select(-c(submission_time, sample_time)) %>%
select(id, score, rank_toppage, on_toppage, rank_newpage, descendants, age_seconds, age_hours,
subtime_datetime, subtime_datetime_rounded, subtime_clocktime, subtime_clocktime_rounded,
samptime_datetime, samptime_datetime_rounded) -> data
data
readr::write_rds(data, file.path("..", "data", "hn-data-processed.rds"), compress = "gz")
# defaults and libraries
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(dplyr)
library(ggplot2)
library(magrittr)
library(gganimate)
source("helpers.R")
# if processed data is not in data folder: process, save and load
# else: load processed data
if (!("hn-data-processed.rds" %in% list.files(file.path("..", "data")))) {
source("preprocess.R")
} else {
data <- readr::read_rds(file.path("..", "data", "hn-data-processed.rds"))
}
# if processed data is not in data folder: process, save and load
# else: load processed data
if (!("hn-data-processed.rds" %in% list.files(file.path("..", "data")))) {
source("preprocess.R")
} else {
data <- readr::read_rds(file.path("..", "data", "hn-data-processed.rds"))
}
rm(data_raw)
# defaults and libraries
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(dplyr)
library(ggplot2)
library(magrittr)
library(gganimate)
source("helpers.R")
# load / preprocess data
if (!("hn-data-processed.rds" %in% list.files(file.path("..", "data")))) {
source("preprocess.R")
} else {
data <- readr::read_rds(file.path("..", "data", "hn-data-processed.rds"))
}
# TODO: EXCLUDE INCOMPLETE DATA FROM "COLD START"?
data %>%
ggplot(aes(x = subtime_datetime)) +
geom_density(color = "black", fill = "black", alpha = 0.5, size = 1) +
labs(title = "KDE of Posting Volume",
x = "Submission Time",
y = "KDE",
caption = "The red dashed line indicates the start of the sampling.") +
geom_vline(xintercept = min(data$samptime_datetime), size = 1, linetype = "dashed", color = "red") +
theme_hn() +
theme(axis.text.y = element_blank())
data %>%
ggplot(aes(x = subtime_clocktime)) +
geom_density(color = "black", fill = "black", alpha = 0.5, size = 1) +
labs(title = "KDE of Posting Volume by Time of Day",
x = "Time of day",
y = "KDE",
caption = "The displayed times are in CET.") +
scale_x_datetime(date_labels = "%H:%M:%S") +
theme_hn() +
theme(axis.text.y = element_blank())
lubridate::as_datetime("2021-01-01 19:00:00 CET")
lubridate::with_tz("2021-01-01 19:00:00 CET", tzone = "GMT-8")
lubridate::with_tz("2021-01-01 19:00:00", tzone = "GMT-8")
OlsonNames()
lubridate::with_tz("2021-01-01 19:00:00", tzone = "America/Los_Angeles")
data %>%
mutate(subtime_date = lubridate::as_date(subtime_datetime),
subtime_hour = lubridate::hour(subtime_datetime)) %>%
select(id, subtime_hour) %>%
distinct() %>%
group_by(subtime_hour) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count_standardized = (count - mean(count)) / sd(count),
subtime_hour_slice = subtime_hour / 24) %>%
select(subtime_hour, subtime_hour_slice, count, count_standardized) -> tmp2
tmp2
data %>%
mutate(subtime_date = lubridate::as_date(subtime_datetime),
subtime_hour = lubridate::hour(subtime_datetime)) %>%
select(id, subtime_hour) %>%
distinct() %>%
group_by(subtime_date, subtime_hour) %>%
summarize(count = n()) %>%
ungroup()
data %>%
mutate(subtime_date = lubridate::as_date(subtime_datetime),
subtime_hour = lubridate::hour(subtime_datetime)) %>%
select(id, subtime_date, subtime_hour) %>%
distinct() %>%
group_by(subtime_date, subtime_hour) %>%
summarize(count = n()) %>%
ungroup()
data %>%
mutate(subtime_date = lubridate::as_date(subtime_datetime),
subtime_hour = lubridate::hour(subtime_datetime)) %>%
select(id, subtime_date, subtime_hour) %>%
distinct() %>%
group_by(subtime_date, subtime_hour) %>%
summarize(count = n()) %>%
ungroup() %>%
group_by(subtime_hour) %>%
summarize(mean_count_per_hour = mean(count)) %>%
ungroup()
data %>%
mutate(subtime_date = lubridate::as_date(subtime_datetime),
subtime_hour = lubridate::hour(subtime_datetime)) %>%
select(id, subtime_date, subtime_hour) %>%
distinct() %>%
group_by(subtime_date, subtime_hour) %>%
summarize(count = n()) %>%
ungroup() %>%
group_by(subtime_hour) %>%
summarize(mean_count_per_hour = mean(count)) %>%
ungroup() -> tmp2
tmp2 %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point() +
ylim(c(100, 700)) +
theme_hn()
tmp2 %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point() +
# ylim(c(100, 700)) +
theme_hn()
tmp2 %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point() +
ylim(c(10, 80)) +
theme_hn()
tmp2
data %>%
mutate(subtime_date = lubridate::as_date(subtime_datetime),
subtime_hour = lubridate::hour(subtime_datetime)) %>%
select(id, subtime_date, subtime_hour) %>%
distinct() %>%
group_by(subtime_date, subtime_hour) %>%
summarize(count = n()) %>%
ungroup() %>%
group_by(subtime_hour) %>%
summarize(mean_count_per_hour = mean(count)) %>%
ungroup() %>%
mutate(mean_count_per_hour_standardized = (mean_count_per_hour - mean(mean_count_per_hour)) / sd(mean_count_per_hour),
subtime_hour_scaled = subtime_hour / 24) %>%
select(subtime_hour, subtime_hour_scaled, mean_count_per_hour, mean_count_per_hour_standardized) -> tmp2
tmp2 %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point() +
ylim(c(10, 80)) +
theme_hn()
tmp2 %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(10, 80)) +
theme_hn()
tmp2 %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
# ylim(c(10, 80)) +
theme_hn()
tmp2 %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
# ylim(c(10, 80)) +
geom_hline(yintercept = mean(mean_count_per_hour_standardized), color = "red") +
theme_hn()
tmp2 %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
# ylim(c(10, 80)) +
geom_hline(yintercept = mean(tmp2$mean_count_per_hour_standardized), color = "red") +
theme_hn()
tmp2 %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
# ylim(c(10, 80)) +
geom_hline(yintercept = 0, linetype = "solid", size = 1) +
theme_hn()
tmp2 %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
geom_hline(yintercept = 0, linetype = "solid", size = 1) +
theme_hn()
data %>%
select(id, subtime_clocktime) %>%
distinct() %>%
arrange(subtime_clocktime) %>%
group_by(subtime_clocktime) %>%
summarize(count = n()) %>%
ungroup() %>%
arrange(subtime_clocktime) -> subs_per_minute
subs_per_minute
data %>%
mutate(subtime_date = lubridate::as_date(subtime_datetime),
subtime_hour = lubridate::hour(subtime_datetime)) %>%
select(id, subtime_date, subtime_hour) %>%
distinct() %>%
group_by(subtime_date, subtime_hour) %>%
summarize(count = n()) %>%
ungroup() %>%
group_by(subtime_hour) %>%
summarize(mean_count_per_hour = mean(count)) %>%
ungroup() %>%
mutate(mean_count_per_hour_standardized = (mean_count_per_hour - mean(mean_count_per_hour)) / sd(mean_count_per_hour),
subtime_hour_scaled = subtime_hour / 24) %>%
select(subtime_hour, subtime_hour_scaled, mean_count_per_hour, mean_count_per_hour_standardized) -> data_posting_volume
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
geom_hline(yintercept = 0, linetype = "solid", size = 1) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point() +
# ylim(c(-2, 2)) +
geom_hline(yintercept = 0, linetype = "solid", size = 1) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point() +
ylim(c(10, 80)) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(color = "blue") +
ylim(c(10, 80)) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(color = "red") +
ylim(c(10, 80)) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 1) +
ylim(c(10, 80)) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
labs(title = "Average Posting Volume per Hour",
x = "Hour of Day",
y = "Average Number of New Stories") +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
scale_x_continuous(breaks = seq(0, 24, by = 6)) +
labs(title = "Average Posting Volume per Hour",
x = "Hour of Day",
y = "Average Number of New Stories") +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
scale_x_continuous(breaks = seq(0, 23, by = 6)) +
labs(title = "Average Posting Volume per Hour",
x = "Hour of Day",
y = "Average Number of New Stories") +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
labs(title = "Average Posting Volume per Hour (Scaled)",
x = "Time of Day [0, 1]",
y = "Average Number of New Stories [Z-Scores]") +
geom_hline(yintercept = 0, linetype = "solid", size = 1) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
scale_x_continuous(breaks = seq(0, 23, by = 6)) +
labs(title = "Average Posting Volume per Hour",
x = "Hour of Day",
y = "Average Number of New Stories") +
geom_hline(yintercept = mean(.$mean_count_per_hour)) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
scale_x_continuous(breaks = seq(0, 23, by = 6)) +
labs(title = "Average Posting Volume per Hour",
x = "Hour of Day",
y = "Average Number of New Stories") +
geom_hline(yintercept = mean(data_posting_volume$mean_count_per_hour)) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
scale_x_continuous(breaks = seq(0, 23, by = 6)) +
labs(title = "Average Posting Volume per Hour",
x = "Hour of Day",
y = "Average Number of New Stories") +
geom_hline(yintercept = mean(data_posting_volume$mean_count_per_hour), linetype = "dashed", color = "red") +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
scale_x_continuous(breaks = seq(0, 23, by = 6)) +
labs(title = "Average Posting Volume per Hour",
x = "Hour of Day",
y = "Average Number of New Stories") +
geom_hline(yintercept = mean(data_posting_volume$mean_count_per_hour), linetype = "dashed", color = "red", size = 2) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
scale_x_continuous(breaks = seq(0, 23, by = 6)) +
labs(title = "Average Posting Volume per Hour",
x = "Hour of Day",
y = "Average Number of New Stories") +
geom_hline(yintercept = mean(data_posting_volume$mean_count_per_hour), linetype = "dashed", color = "red", size = 1) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour, y = mean_count_per_hour)) +
geom_point(size = 2) +
ylim(c(10, 80)) +
scale_x_continuous(breaks = seq(0, 23, by = 6)) +
labs(title = "Average Posting Volume per Hour",
x = "Hour of Day",
y = "Average Number of New Stories",
caption = "The red dashed line indicates the daily average.") +
geom_hline(yintercept = mean(data_posting_volume$mean_count_per_hour),
linetype = "dashed", color = "red", size = 1) +
theme_hn()
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
labs(title = "Average Posting Volume per Hour (Scaled)",
x = "Time of Day [0, 1]",
y = "Average Number of New Stories [Z-Scores]") +
geom_function(fun = adj_sin)
adj_sin <- function(x) {
1.5 * sin(-6.4 * x)
}
adj_sin2 <- function(x) {
sin(-6.4 * x)
}
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
labs(title = "Average Posting Volume per Hour (Scaled)",
x = "Time of Day [0, 1]",
y = "Average Number of New Stories [Z-Scores]") +
geom_function(fun = adj_sin)
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
labs(title = "Average Posting Volume per Hour (Scaled)",
x = "Time of Day [0, 1]",
y = "Average Number of New Stories [Z-Scores]") +
geom_function(fun = adj_sin2)
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
labs(title = "Average Posting Volume per Hour (Scaled)",
x = "Time of Day [0, 1]",
y = "Average Number of New Stories [Z-Scores]") +
geom_function(fun = adj_sin2, color = "blue")
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
labs(title = "Average Posting Volume per Hour (Scaled)",
x = "Time of Day [0, 1]",
y = "Average Number of New Stories [Z-Scores]") +
geom_function(fun = adj_sin2, color = "blue", size = 1)
adj_sin2 <- function(x) {
sin(-6.4 * x)
}
adj_sin <- function(x) {
1.5 * sin(-6.4 * x)
}
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
labs(title = "Average Posting Volume per Hour (Scaled)",
x = "Time of Day [0, 1]",
y = "Average Number of New Stories [Z-Scores]") +
geom_function(fun = adj_sin, color = "blue", size = 1) +
geom_function(fun = adj_sin2, color = "red", size = 1) +
geom_hline(yintercept = 0, linetype = "solid", size = 1) +
theme_hn()
adj_sin <- function(x) {
sin(-6.4 * x)
}
adj_sin2 <- function(x) {
1.5 * sin(-6.4 * x)
}
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
labs(title = "Average Posting Volume per Hour (Scaled)",
x = "Time of Day [0, 1]",
y = "Average Number of New Stories [Z-Scores]") +
geom_function(fun = adj_sin, color = "blue", size = 1) +
geom_function(fun = adj_sin2, color = "red", size = 1) +
geom_hline(yintercept = 0, linetype = "solid", size = 1) +
theme_hn()
adj_sin <- function(x) {
-sin(6.4 * x)
}
adj_sin2 <- function(x) {
1.5 * (-sin(6.4 * x))
}
data_posting_volume %>%
ggplot(aes(x = subtime_hour_scaled, y = mean_count_per_hour_standardized)) +
geom_point() +
ylim(c(-2, 2)) +
labs(title = "Average Posting Volume per Hour (Scaled)",
x = "Time of Day [0, 1]",
y = "Average Number of New Stories [Z-Scores]") +
geom_function(fun = adj_sin, color = "blue", size = 1) +
geom_function(fun = adj_sin2, color = "red", size = 1) +
geom_hline(yintercept = 0, linetype = "solid", size = 1) +
theme_hn()
lubridate::with_tz("2021-01-01 19:00:00", tzone = "America/Los_Angeles")
# get IDs and submission times and sort them by temporally
data %>%
select(id, subtime_datetime) %>%
unique() %>%
arrange(subtime_datetime) %>%
select(subtime_datetime) -> sorted_submission_times
# compute for every 1 minute timeslice how many new stories are posted
tibble(subtime = sorted_submission_times$subtime_datetime,
bin = cut(sorted_submission_times$subtime_datetime,
breaks = "1 min",
labels = FALSE)) %>%
mutate(bin = factor(bin, levels = seq(1, max(bin), by = 1))) %>%
group_by(bin, .drop = FALSE) %>%
summarize(arr_count = n()) -> arrival_counts
# get IDs and submission times and sort them by temporally
data %>%
select(id, subtime_datetime) %>%
distinct() %>%
arrange(subtime_datetime) %>%
select(subtime_datetime) -> sorted_submission_times
# compute for every 1 minute timeslice how many new stories are posted
tibble(subtime = sorted_submission_times$subtime_datetime,
bin = cut(sorted_submission_times$subtime_datetime,
breaks = "1 min",
labels = FALSE)) %>%
mutate(bin = factor(bin, levels = seq(1, max(bin), by = 1))) %>%
group_by(bin, .drop = FALSE) %>%
summarize(arr_count = n()) -> arrival_counts
arrival_counts
24 * 60
arrival_counts
sorted_submission_times
# generics
y_max <- 7000
rate_max <- 7
# show real distribution of arrival times
p1 <- arrival_counts %>%
ggplot(aes(x = arr_count)) +
geom_bar(color = "transparent", fill = "black", alpha = 0.8) +
ylim(c(0, y_max)) +
scale_x_continuous(breaks = seq(0, 7, by = 1), limits = c(-0.5, rate_max + 0.5)) +
labs(title = "Distribution of Arrival Rate per Minute (Empirical)",
x = "Arrival Rate",
y = "Count") +
coord_flip() +
theme_hn() +
theme(panel.grid.minor.x = element_blank(),
panel.grid.minor.y = element_blank())
# simulate this process
set.seed(1)
n <- dim(arrival_counts)[1]
lambda <- mean(arrival_counts$arr_count)
simulated_distribution <- tibble(arr_count = rpois(n, lambda))
# show simulated distribution of arrival times
p2 <- simulated_distribution %>%
ggplot(aes(x = arr_count)) +
geom_bar(color = "transparent", fill = "black", alpha = 0.8) +
ylim(c(0, y_max)) +
scale_x_continuous(breaks = seq(0, 7, by = 1), limits = c(-0.5, rate_max + 0.5)) +
labs(title = "Distribution of Arrival Rate per Minute (Simulated)",
x = "Arrival Rate",
y = "Count")  +
coord_flip() +
theme_hn() +
theme(panel.grid.minor.x = element_blank(),
panel.grid.minor.y = element_blank())
ggpubr::ggarrange(p1, p2, ncol = 1)
